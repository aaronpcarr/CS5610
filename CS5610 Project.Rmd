---
title: "CS 5610 Project"
author: "Aaron Carr & Daniel Reardon"
date: "4/8/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r}
library(boot)
library(MASS)
library(e1071)
library(caTools)
library(dplyr)
library(tree)
library(randomForest)
library(gbm)
library(ggplot2)
library(gridExtra)
```



```{r}
#Load Dataset
heart <- read.csv("heart.csv")
heart_copy = read.csv("heart.csv")

heart <- mutate(heart, typical_angina = as.integer(ChestPainType == "TA")) %>%
  mutate(atypical_angina = as.integer(ChestPainType == "ATA")) %>%
  mutate(non_angina_pain = as.integer(ChestPainType == "NAP")) %>%
  mutate(st_abnorm =  as.integer(RestingECG == "ST")) %>%
  mutate(left_vent_hypertroph = as.integer(RestingECG == "LVH")) %>%
  mutate(ExerciseAngina = as.integer(ExerciseAngina == "Y")) %>%
  mutate(stslope_up = as.integer(ST_Slope == "Up")) %>%
  mutate(stslope_down = as.integer(ST_Slope == "Down")) %>%
  mutate(male = as.integer(Sex == "M")) %>%
  select(- c(ChestPainType, RestingECG, ST_Slope, Sex))

#Give it a look over
View(heart)
names(heart)
dim(heart)
summary(heart)
#Check to see if there's any missing values
any(is.na(heart))

set.seed(97)
spl = sample.split(heart$HeartDisease, SplitRatio = 0.75)

heartTrain = subset(heart, spl==TRUE)
heartTest = subset(heart, spl==FALSE)

dim(heartTrain)
dim(heartTest)
```

```{r}
one = ggplot(data = heart_copy) +
 geom_col(mapping = aes(x = Sex, y = HeartDisease, fill = Sex)) + labs(y = "Heart Disease")
zero = ggplot(data = heart_copy) +
 geom_col(mapping = aes(x = Sex, y = 1 - HeartDisease, fill = Sex)) + labs(y = "Non-Heart Disease")

grid.arrange(one,zero, ncol= 2)
```

```{r}
two = ggplot(data = heart_copy) +
 geom_col(mapping = aes(x = ChestPainType, y = HeartDisease, fill = ChestPainType)) + labs(y = "Heart Disease")
three = ggplot(data = heart_copy) +
 geom_col(mapping = aes(x = ChestPainType, y = 1 - HeartDisease, fill = ChestPainType)) + labs(y = "Non-Heart Disease")

grid.arrange(two,three, ncol= 2)
```
```



```{r}
#Logistic Regression (87%)
glm.fits <- glm(HeartDisease ~ .,
  family = binomial, data = heartTrain
)
cv.err <- cv.glm(heartTrain, glm.fits)
cv.err$delta
summary(glm.fits)

glm.probs <- predict(glm.fits, type = "response")
glm.pred <- rep(0, 689)
glm.pred[glm.probs > .5] = 1

table(glm.pred, heartTrain$HeartDisease)
mean(glm.pred == heartTrain$HeartDisease)

glm.probs <- predict(glm.fits, type = "response", newdata = heartTest)
glm.predTest <- rep(0, 229)
glm.predTest[glm.probs > .5] = 1

table(glm.predTest, heartTest$HeartDisease)
mean(glm.predTest == heartTest$HeartDisease)

##Feature Selection algorithm
i <- glm(HeartDisease ~ 1,
                 family = binomial, data = heartTrain)

glm.new <- step(i, direction='both', scope=formula(glm.fits), trace=0)

summary(glm.new)

glm.probs <- predict(glm.new, type = "response", newdata = heartTest)
glm.predTest <- rep(0, 229)
glm.predTest[glm.probs > .5] = 1

table(glm.predTest, heartTest$HeartDisease)
mean(glm.predTest == heartTest$HeartDisease)

```



```{r}
#Linear Discriminant Analysis (87%)
lda.fit <- lda(HeartDisease ~ ., data = heartTrain)
lda.fit
plot(lda.fit)

lda.pred <- predict(lda.fit, newdata = heartTest)
lda.class <- lda.pred$class
table(lda.class, heartTest$HeartDisease)
mean(lda.class == heartTest$HeartDisease)
```



```{r}
#Quadratic Discriminant Analysis (86%)

qda.fit <- qda(HeartDisease ~ ., data = heartTrain)
qda.fit

qda.class <- predict(qda.fit, newdata = heartTest)$class
table(qda.class, heartTest$HeartDisease)
mean(qda.class == heartTest$HeartDisease)
```



```{r}
#Naive Bayes (87%)
nb.fit <- naiveBayes(HeartDisease ~ ., data = heartTrain)
nb.fit

nb.class <- predict(nb.fit, newdata = heartTest)
table(nb.class, heartTest$HeartDisease)
mean(nb.class == heartTest$HeartDisease)

```

```{r}
#Classification Tree 85%
tree.heart <- tree(as.factor(HeartDisease) ~ ., data = heartTrain)
summary(tree.heart)

tree:::print.tree(tree.heart)

tree.pred <- predict(tree.heart, heartTest, type = "class")
table(tree.pred, heartTest$HeartDisease)
(72+117)/229
```

```{r}
#Random Forest 84%
rf.heart <- randomForest(as.factor(HeartDisease) ~ ., data = heartTrain, importance = TRUE)
rf.pred <- predict(rf.heart, heartTest, type = "class")
table(tree.pred, heartTest$HeartDisease)
(72 + 117)/229
importance(rf.heart)

varImpPlot(rf.heart)
```

```{r}
# boost.heart <- gbm(HeartDisease ~ ., data = heartTrain, distribution = "bernoulli")
# boost.pred <- predict(boost.heart, heartTest, type = "response")
# 

```